{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3af27b7",
   "metadata": {},
   "source": [
    "# 시작 CPU버전\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33af1d40",
   "metadata": {},
   "source": [
    "## 사용법\n",
    "- ctrl + enter : 셀실행\n",
    "- 하나의 칸을 셀이라고 말합니다\n",
    "- 셀을 실행하면 블럭이 쌓이는 느낌\n",
    "- 셀은 이전 것이 진행되야 다음이 됩니다.\n",
    "- 메뉴 ->  kernel -> restart를 하면 초기화\n",
    "- 쓰레기가 많아지면 초기화를 추천합니다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656981a6",
   "metadata": {},
   "source": [
    "## 의존성 설치\n",
    "\n",
    "- 하나하나 해봐요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04a94782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\kasnd\\anaconda3\\envs\\pytorch\\lib\\site-packages (1.10.2)\n",
      "Requirement already satisfied: torchvision in c:\\users\\kasnd\\anaconda3\\envs\\pytorch\\lib\\site-packages (0.11.3)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\kasnd\\anaconda3\\envs\\pytorch\\lib\\site-packages (0.10.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\kasnd\\anaconda3\\envs\\pytorch\\lib\\site-packages (from torch) (4.1.1)\n",
      "Requirement already satisfied: dataclasses in c:\\users\\kasnd\\anaconda3\\envs\\pytorch\\lib\\site-packages (from torch) (0.8)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in c:\\users\\kasnd\\anaconda3\\envs\\pytorch\\lib\\site-packages (from torchvision) (8.4.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\kasnd\\anaconda3\\envs\\pytorch\\lib\\site-packages (from torchvision) (1.19.5)\n",
      "Requirement already satisfied: librosa in c:\\users\\kasnd\\anaconda3\\envs\\pytorch\\lib\\site-packages (0.9.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\kasnd\\anaconda3\\envs\\pytorch\\lib\\site-packages (from librosa) (21.3)\n",
      "Requirement already satisfied: audioread>=2.1.9 in c:\\users\\kasnd\\anaconda3\\envs\\pytorch\\lib\\site-packages (from librosa) (3.0.1)\n",
      "Requirement already satisfied: joblib>=0.14 in c:\\users\\kasnd\\anaconda3\\envs\\pytorch\\lib\\site-packages (from librosa) (1.1.1)\n",
      "Requirement already satisfied: decorator>=4.0.10 in c:\\users\\kasnd\\anaconda3\\envs\\pytorch\\lib\\site-packages (from librosa) (5.1.1)\n",
      "Requirement already satisfied: pooch>=1.0 in c:\\users\\kasnd\\anaconda3\\envs\\pytorch\\lib\\site-packages (from librosa) (1.6.0)\n",
      "Requirement already satisfied: resampy>=0.2.2 in c:\\users\\kasnd\\anaconda3\\envs\\pytorch\\lib\\site-packages (from librosa) (0.4.3)\n",
      "Requirement already satisfied: scipy>=1.2.0 in c:\\users\\kasnd\\anaconda3\\envs\\pytorch\\lib\\site-packages (from librosa) (1.5.4)\n",
      "Requirement already satisfied: soundfile>=0.10.2 in c:\\users\\kasnd\\anaconda3\\envs\\pytorch\\lib\\site-packages (from librosa) (0.12.1)\n",
      "Requirement already satisfied: numba>=0.45.1 in c:\\users\\kasnd\\anaconda3\\envs\\pytorch\\lib\\site-packages (from librosa) (0.53.1)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\kasnd\\anaconda3\\envs\\pytorch\\lib\\site-packages (from librosa) (1.19.5)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in c:\\users\\kasnd\\anaconda3\\envs\\pytorch\\lib\\site-packages (from librosa) (0.24.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\kasnd\\anaconda3\\envs\\pytorch\\lib\\site-packages (from numba>=0.45.1->librosa) (58.0.4)\n",
      "Requirement already satisfied: llvmlite<0.37,>=0.36.0rc1 in c:\\users\\kasnd\\anaconda3\\envs\\pytorch\\lib\\site-packages (from numba>=0.45.1->librosa) (0.36.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\kasnd\\anaconda3\\envs\\pytorch\\lib\\site-packages (from packaging>=20.0->librosa) (3.1.2)\n",
      "Requirement already satisfied: appdirs>=1.3.0 in c:\\users\\kasnd\\anaconda3\\envs\\pytorch\\lib\\site-packages (from pooch>=1.0->librosa) (1.4.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\kasnd\\anaconda3\\envs\\pytorch\\lib\\site-packages (from pooch>=1.0->librosa) (2.27.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kasnd\\anaconda3\\envs\\pytorch\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kasnd\\anaconda3\\envs\\pytorch\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2021.5.30)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\kasnd\\anaconda3\\envs\\pytorch\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\kasnd\\anaconda3\\envs\\pytorch\\lib\\site-packages (from requests>=2.19.0->pooch>=1.0->librosa) (1.26.19)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\kasnd\\anaconda3\\envs\\pytorch\\lib\\site-packages (from resampy>=0.2.2->librosa) (5.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\kasnd\\anaconda3\\envs\\pytorch\\lib\\site-packages (from scikit-learn>=0.19.1->librosa) (3.1.0)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\kasnd\\anaconda3\\envs\\pytorch\\lib\\site-packages (from soundfile>=0.10.2->librosa) (1.15.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\kasnd\\anaconda3\\envs\\pytorch\\lib\\site-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.21)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\kasnd\\anaconda3\\envs\\pytorch\\lib\\site-packages (from importlib-resources->resampy>=0.2.2->librosa) (3.6.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\kasnd\\anaconda3\\envs\\pytorch\\lib\\site-packages (1.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\kasnd\\anaconda3\\envs\\pytorch\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\kasnd\\anaconda3\\envs\\pytorch\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: numpy>=1.15.4 in c:\\users\\kasnd\\anaconda3\\envs\\pytorch\\lib\\site-packages (from pandas) (1.19.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kasnd\\anaconda3\\envs\\pytorch\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\kasnd\\anaconda3\\envs\\pytorch\\lib\\site-packages (4.64.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\kasnd\\anaconda3\\envs\\pytorch\\lib\\site-packages (from tqdm) (0.4.4)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\kasnd\\anaconda3\\envs\\pytorch\\lib\\site-packages (from tqdm) (5.4.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\kasnd\\anaconda3\\envs\\pytorch\\lib\\site-packages (from importlib-resources->tqdm) (3.6.0)\n",
      "Requirement already satisfied: torchmetrics in c:\\users\\kasnd\\anaconda3\\envs\\pytorch\\lib\\site-packages (0.8.2)\n",
      "Requirement already satisfied: pyDeprecate==0.3.* in c:\\users\\kasnd\\anaconda3\\envs\\pytorch\\lib\\site-packages (from torchmetrics) (0.3.2)\n",
      "Requirement already satisfied: numpy>=1.17.2 in c:\\users\\kasnd\\anaconda3\\envs\\pytorch\\lib\\site-packages (from torchmetrics) (1.19.5)\n",
      "Requirement already satisfied: torch>=1.3.1 in c:\\users\\kasnd\\anaconda3\\envs\\pytorch\\lib\\site-packages (from torchmetrics) (1.10.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\kasnd\\anaconda3\\envs\\pytorch\\lib\\site-packages (from torchmetrics) (21.3)\n",
      "Requirement already satisfied: dataclasses in c:\\users\\kasnd\\anaconda3\\envs\\pytorch\\lib\\site-packages (from torch>=1.3.1->torchmetrics) (0.8)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\kasnd\\anaconda3\\envs\\pytorch\\lib\\site-packages (from torch>=1.3.1->torchmetrics) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\kasnd\\anaconda3\\envs\\pytorch\\lib\\site-packages (from packaging->torchmetrics) (3.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio\n",
    "!pip install librosa\n",
    "!pip install pandas\n",
    "!pip install tqdm\n",
    "!pip install torchmetrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3ad0e7",
   "metadata": {},
   "source": [
    "- 라이브러리 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d572dd69-1427-4626-bfd8-39e9a3869001",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torchmetrics\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53bd8fd4-7dfb-4b7c-a1b8-7d623f601467",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97821ffb",
   "metadata": {},
   "source": [
    "- 디바이스 선택\n",
    "- 지금은 cpu만 될 것입니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18b9390b-8ed9-4537-980d-71c488ba3ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4615a06a",
   "metadata": {},
   "source": [
    "- 학습에 관한 설정파일\n",
    "- sr = 음성이 초당 짤려지는 비율 이건 고정입니다\n",
    "- n_mfcc = 음성의 특징을 가져올 개수\n",
    "- batch_size = 한번에 학습하는 양\n",
    "- n_epochs = 몇번 학습할 건가요?\n",
    "- lr = 한번 학습할때 얼마나 조정을 하나요\n",
    "- seed = 랜덤값 고정입니다. 아시잖아요 컴퓨터는 랜덤아니니까"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7268e0fb-6c2e-4929-92a8-6edb3fb80bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    SR = 32000\n",
    "    N_MFCC = 52\n",
    "    # Dataset\n",
    "    ROOT_FOLDER = './'\n",
    "    # Training\n",
    "    N_CLASSES = 2\n",
    "    BATCH_SIZE = 96\n",
    "    N_EPOCHS = 5\n",
    "    LR = 3e-4\n",
    "    # Others\n",
    "    SEED = 42\n",
    "    \n",
    "CONFIG = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf7d943",
   "metadata": {},
   "source": [
    "- 랜덤 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b40841f-04dd-41a4-b8b5-afb87dd0b322",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(CONFIG.SEED) # Seed 고정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49408c8f",
   "metadata": {},
   "source": [
    "- 데이터 파일 불러오기\n",
    "- 학습인 train.csv에서 정보를 그대로 불러옵니다\n",
    "- pandas라는 라이브러리의 데이터프레임을 사용합니다\n",
    "- 데이터프레임은 csv와 같은 테이블입니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "351f55b9-9071-42fe-9b03-6a1ce936d704",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./train.csv')\n",
    "train, val, _, _ = train_test_split(df, df['label'], test_size=0.2, random_state=CONFIG.SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182a27f8",
   "metadata": {},
   "source": [
    "- 음성이잖아요? 그러니 음성에 맞는 특징을 가져옵니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23477019-8ba7-4fb0-afc2-157628439679",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mfcc_feature(df, train_mode=True):\n",
    "    features = []\n",
    "    labels = []\n",
    "    for _, row in tqdm(df.iterrows()):\n",
    "        # librosa패키지를 사용하여 wav 파일 load\n",
    "        y, sr = librosa.load(row['path'], sr=CONFIG.SR)\n",
    "        \n",
    "        # librosa패키지를 사용하여 mfcc 추출\n",
    "        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=CONFIG.N_MFCC)\n",
    "        mfcc = np.mean(mfcc.T, axis=0)\n",
    "        features.append(mfcc)\n",
    "\n",
    "        if train_mode:\n",
    "            label = row['label']\n",
    "            label_vector = np.zeros(CONFIG.N_CLASSES, dtype=float)\n",
    "            label_vector[0 if label == 'fake' else 1] = 1\n",
    "            labels.append(label_vector)\n",
    "\n",
    "    if train_mode:\n",
    "        return features, labels\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cd3a21",
   "metadata": {},
   "source": [
    "- 함수를 실행해서 실제 값을 가져오는 겁니다.\n",
    "- 특징을 뽑는 건데 좀 걸려요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64dbb07a-f70b-446f-b1a1-f9a00e335ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "44350it [06:08, 120.29it/s]\n",
      "11088it [01:30, 122.63it/s]\n"
     ]
    }
   ],
   "source": [
    "train_mfcc, train_labels = get_mfcc_feature(train, True)\n",
    "val_mfcc, val_labels = get_mfcc_feature(val, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48787f00",
   "metadata": {},
   "source": [
    "- 데이터에 대한 세트설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a1039b2-c127-4abc-947f-8ff769385458",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, mfcc, label):\n",
    "        self.mfcc = mfcc\n",
    "        self.label = label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.mfcc)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.label is not None:\n",
    "            return self.mfcc[index], self.label[index]\n",
    "        return self.mfcc[index]\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b210ef1e-0823-4a98-868c-55be2784d6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train_mfcc, train_labels)\n",
    "val_dataset = CustomDataset(val_mfcc, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10dd0a11-7451-4c9b-8e67-b6213e0d42c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=CONFIG.BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=CONFIG.BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3cd62c",
   "metadata": {},
   "source": [
    "- 평가를 하는 것과 학습하는 것에 대한 세부사항"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50038438-d128-4909-b4d8-5c39bb3640ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def train(model, optimizer, train_loader, val_loader, device):\n",
    "    model.to(device)\n",
    "    criterion = nn.BCELoss().to(device)\n",
    "    \n",
    "    best_val_score = 0\n",
    "    best_model = None\n",
    "    \n",
    "    for epoch in range(1, CONFIG.N_EPOCHS+1):\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "        for features, labels in tqdm(iter(train_loader)):\n",
    "            features = features.float().to(device)\n",
    "            labels = labels.float().to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            output = model(features)\n",
    "            loss = criterion(output, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss.append(loss.item())\n",
    "                    \n",
    "        _val_loss, _val_score = validation(model, criterion, val_loader, device)\n",
    "        _train_loss = np.mean(train_loss)\n",
    "        print(f'Epoch [{epoch}], Train Loss : [{_train_loss:.5f}] Val Loss : [{_val_loss:.5f}] Val AUC : [{_val_score:.5f}]')\n",
    "            \n",
    "        if best_val_score < _val_score:\n",
    "            best_val_score = _val_score\n",
    "            best_model = model\n",
    "    \n",
    "    return best_model\n",
    "\n",
    "def multiLabel_AUC(y_true, y_scores):\n",
    "    auc_scores = []\n",
    "    for i in range(y_true.shape[1]):\n",
    "        auc = roc_auc_score(y_true[:, i], y_scores[:, i])\n",
    "        auc_scores.append(auc)\n",
    "    mean_auc_score = np.mean(auc_scores)\n",
    "    return mean_auc_score\n",
    "    \n",
    "def validation(model, criterion, val_loader, device):\n",
    "    model.eval()\n",
    "    val_loss, all_labels, all_probs = [], [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for features, labels in tqdm(iter(val_loader)):\n",
    "            features = features.float().to(device)\n",
    "            labels = labels.float().to(device)\n",
    "            \n",
    "            probs = model(features)\n",
    "            \n",
    "            loss = criterion(probs, labels)\n",
    "\n",
    "            val_loss.append(loss.item())\n",
    "\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "            all_probs.append(probs.cpu().numpy())\n",
    "        \n",
    "        _val_loss = np.mean(val_loss)\n",
    "\n",
    "        all_labels = np.concatenate(all_labels, axis=0)\n",
    "        all_probs = np.concatenate(all_probs, axis=0)\n",
    "        \n",
    "        # Calculate AUC score\n",
    "        auc_score = multiLabel_AUC(all_labels, all_probs)\n",
    "    \n",
    "    return _val_loss, auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ec4089",
   "metadata": {},
   "source": [
    "- 학습을 할 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e35af38-71ba-4a39-86d1-5b140e222825",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim=CONFIG.N_MFCC, hidden_dim=128, output_dim=CONFIG.N_CLASSES):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d7ff89",
   "metadata": {},
   "source": [
    "- 학습시작\n",
    "- 학습에서 train, val이 있습니다. train_loss는 학습데이터에 대한 오차, val_loss는 학습에 사용되지 않는 검증 데이터의 오차입니다.\n",
    "- 같이 줄어들어야 좋습니다. val이 높아지면 큰일입니다\n",
    "- auc 정확도입니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a72b031-7a0b-4d61-a632-e305b97c3a8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 462/462 [00:01<00:00, 285.88it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 116/116 [00:00<00:00, 852.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1], Train Loss : [0.38785] Val Loss : [0.16761] Val AUC : [0.98719]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 462/462 [00:01<00:00, 292.95it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 116/116 [00:00<00:00, 838.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2], Train Loss : [0.17428] Val Loss : [0.08412] Val AUC : [0.99617]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 462/462 [00:01<00:00, 294.39it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 116/116 [00:00<00:00, 1193.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3], Train Loss : [0.12251] Val Loss : [0.05593] Val AUC : [0.99807]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 462/462 [00:01<00:00, 332.87it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 116/116 [00:00<00:00, 631.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4], Train Loss : [0.09748] Val Loss : [0.04663] Val AUC : [0.99854]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 462/462 [00:01<00:00, 268.24it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 116/116 [00:00<00:00, 1067.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5], Train Loss : [0.08627] Val Loss : [0.03638] Val AUC : [0.99900]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = MLP()\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr = CONFIG.LR)\n",
    "\n",
    "infer_model = train(model, optimizer, train_loader, val_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfc8b71",
   "metadata": {},
   "source": [
    "- 모델 저장\n",
    "- 이름은 알아서 해주세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "959cf6fc-2389-421c-ad97-2ccc073d99c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(infer_model.state_dict(),\"./mlp_model_01.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d78bb1",
   "metadata": {},
   "source": [
    "- 제출을 위한 데이터 부분\n",
    "- 실제 제출이 현재는 의미가 없어서 평가를 보여드립니다\n",
    "- 실행해주세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16a3720f-7e31-4ec7-8285-c6ee222af916",
   "metadata": {},
   "outputs": [],
   "source": [
    "val.to_csv('val.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eab37e6d-6419-4c97-a037-1bcfd7b6460a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, test_loader, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for features in tqdm(iter(test_loader)):\n",
    "            features = features.float().to(device)\n",
    "            \n",
    "            probs = model(features)\n",
    "\n",
    "            probs  = probs.cpu().detach().numpy()\n",
    "            predictions += probs.tolist()\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff0f3d86-330f-4450-a219-e3bd05f43c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11088it [01:35, 116.10it/s]\n"
     ]
    }
   ],
   "source": [
    "val2 = pd.read_csv('./val.csv')\n",
    "val2_mfcc = get_mfcc_feature(val2, False)\n",
    "val2_dataset = CustomDataset(val2_mfcc, None)\n",
    "val2_loader = DataLoader(\n",
    "    val2_dataset,\n",
    "    batch_size=CONFIG.BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ff38a6d1-47ce-4951-aefd-f8436f067779",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 116/116 [00:00<00:00, 1626.31it/s]\n"
     ]
    }
   ],
   "source": [
    "preds = inference(infer_model, val2_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0404e337-14a5-44b2-b676-6bf463391fec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PUOXNOKJ</td>\n",
       "      <td>0.000177234</td>\n",
       "      <td>0.999806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GXOIPDJP</td>\n",
       "      <td>0.990675</td>\n",
       "      <td>0.011206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FOEQKPPR</td>\n",
       "      <td>0.997121</td>\n",
       "      <td>0.00270101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IYASAVDT</td>\n",
       "      <td>0.00224651</td>\n",
       "      <td>0.997751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VLWIXPTC</td>\n",
       "      <td>0.124349</td>\n",
       "      <td>0.885412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id         path       label\n",
       "0  PUOXNOKJ  0.000177234    0.999806\n",
       "1  GXOIPDJP     0.990675    0.011206\n",
       "2  FOEQKPPR     0.997121  0.00270101\n",
       "3  IYASAVDT   0.00224651    0.997751\n",
       "4  VLWIXPTC     0.124349    0.885412"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit = pd.read_csv('./val.csv')\n",
    "submit.iloc[:, 1:] = preds\n",
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "65744a47-ffbf-4504-b44c-7e0491c1deb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=submit.rename(columns={'path':'fake','label':'real'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c409958",
   "metadata": {},
   "source": [
    "- 정확도를 산출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c5e594c0-0260-4e07-a818-12e7e96782ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도: 98.93%\n"
     ]
    }
   ],
   "source": [
    "# 예측값을 기준으로 'real'과 'fake'로 변환\n",
    "binary_preds = []\n",
    "for i in preds:\n",
    "    if i[0] < i[1]:\n",
    "        binary_preds.append('real')\n",
    "    else:\n",
    "        binary_preds.append('fake')\n",
    "        \n",
    "\n",
    "# test.csv에서 실제 정답 레이블을 가져옴\n",
    "true_labels = val['label'].values\n",
    "\n",
    "# 예측값과 실제값이 일치하는지 확인\n",
    "accuracy = np.mean(binary_preds == true_labels)\n",
    "\n",
    "# 일치율을 퍼센트 형식으로 출력\n",
    "print(f\"정확도: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8a36fa",
   "metadata": {},
   "source": [
    "- 데이터의 일치를 보실 수 있습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "78cb6236-d98b-49b3-b4b1-6d74a40062b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "      <th>pd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PUOXNOKJ</td>\n",
       "      <td>./train/PUOXNOKJ.ogg</td>\n",
       "      <td>real</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GXOIPDJP</td>\n",
       "      <td>./train/GXOIPDJP.ogg</td>\n",
       "      <td>fake</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FOEQKPPR</td>\n",
       "      <td>./train/FOEQKPPR.ogg</td>\n",
       "      <td>fake</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IYASAVDT</td>\n",
       "      <td>./train/IYASAVDT.ogg</td>\n",
       "      <td>real</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VLWIXPTC</td>\n",
       "      <td>./train/VLWIXPTC.ogg</td>\n",
       "      <td>real</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11083</th>\n",
       "      <td>WQMWFZRS</td>\n",
       "      <td>./train/WQMWFZRS.ogg</td>\n",
       "      <td>fake</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11084</th>\n",
       "      <td>KYLYAJSQ</td>\n",
       "      <td>./train/KYLYAJSQ.ogg</td>\n",
       "      <td>fake</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11085</th>\n",
       "      <td>AEFBUARF</td>\n",
       "      <td>./train/AEFBUARF.ogg</td>\n",
       "      <td>real</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11086</th>\n",
       "      <td>VDPZMHZX</td>\n",
       "      <td>./train/VDPZMHZX.ogg</td>\n",
       "      <td>fake</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11087</th>\n",
       "      <td>NAEMKYCJ</td>\n",
       "      <td>./train/NAEMKYCJ.ogg</td>\n",
       "      <td>real</td>\n",
       "      <td>real</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11088 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                  path label    pd\n",
       "0      PUOXNOKJ  ./train/PUOXNOKJ.ogg  real  real\n",
       "1      GXOIPDJP  ./train/GXOIPDJP.ogg  fake  fake\n",
       "2      FOEQKPPR  ./train/FOEQKPPR.ogg  fake  fake\n",
       "3      IYASAVDT  ./train/IYASAVDT.ogg  real  real\n",
       "4      VLWIXPTC  ./train/VLWIXPTC.ogg  real  real\n",
       "...         ...                   ...   ...   ...\n",
       "11083  WQMWFZRS  ./train/WQMWFZRS.ogg  fake  fake\n",
       "11084  KYLYAJSQ  ./train/KYLYAJSQ.ogg  fake  fake\n",
       "11085  AEFBUARF  ./train/AEFBUARF.ogg  real  real\n",
       "11086  VDPZMHZX  ./train/VDPZMHZX.ogg  fake  fake\n",
       "11087  NAEMKYCJ  ./train/NAEMKYCJ.ogg  real  real\n",
       "\n",
       "[11088 rows x 4 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val2['pd'] = binary_preds\n",
    "val2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134b50b7",
   "metadata": {},
   "source": [
    "- 제출시에 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6fdeb78a-60bc-4c8f-beff-bb168bf08efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50000it [14:03, 59.25it/s]\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('./test.csv')\n",
    "test_mfcc = get_mfcc_feature(test, False)\n",
    "test_dataset = CustomDataset(test_mfcc, None)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=CONFIG.BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fd5b8d20-e1da-470d-a8c2-5682a22cce22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████| 521/521 [00:00<00:00, 1153.03it/s]\n"
     ]
    }
   ],
   "source": [
    "test_model = MLP()\n",
    "test_model.load_state_dict(torch.load(\"./mlp_model_01.pth\"))\n",
    "test_model.to(device)\n",
    "test_model.eval()\n",
    "preds = inference(test_model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6f4a1c04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>fake</th>\n",
       "      <th>real</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_00000</td>\n",
       "      <td>0.969886</td>\n",
       "      <td>0.038206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_00001</td>\n",
       "      <td>0.832707</td>\n",
       "      <td>0.202042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_00002</td>\n",
       "      <td>0.902915</td>\n",
       "      <td>0.120648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_00003</td>\n",
       "      <td>0.085946</td>\n",
       "      <td>0.914218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_00004</td>\n",
       "      <td>0.002521</td>\n",
       "      <td>0.997545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id      fake      real\n",
       "0  TEST_00000  0.969886  0.038206\n",
       "1  TEST_00001  0.832707  0.202042\n",
       "2  TEST_00002  0.902915  0.120648\n",
       "3  TEST_00003  0.085946  0.914218\n",
       "4  TEST_00004  0.002521  0.997545"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit = pd.read_csv('./sample_submission.csv')\n",
    "submit.iloc[:, 1:] = preds\n",
    "submit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "29142d5f-6a90-4216-b27a-5946410ef04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit.to_csv('ssut.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33f158a",
   "metadata": {},
   "source": [
    "- dataset에 데이터를 저장합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "25a40d3e-9f23-44f0-8841-5761faf9dfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#처리값\n",
    "np.save('./dataset/train_mfcc.npy',train_mfcc)\n",
    "np.save('./dataset/val_mfcc.npy',val_mfcc)\n",
    "np.save('./dataset/test_mfcc.npy',test_mfcc)\n",
    "np.save('./dataset/train_label.npy',train_labels)\n",
    "np.save('./dataset/val_label.npy',val_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
